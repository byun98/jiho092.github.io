---
layout: single
title: "I Can See Clearly Now : Image Restoration via De-Raining" #제목
excerpt : ""
categories: 
    - Inpainting #카테고리설정
tag: 
    - [""] #테그

use_math: true

date: 2024-11-07
last_modified_at: 2024-11-07
#classes: wide    
---
[I Can See Clearly Now : Image Restoration via De-Raining](https://arxiv.org/pdf/1901.00893){: .btn .btn--primary}

**이 논문에서의 목적은 이미지를 pre-processing하면 rain augmented data로 모델을 training, retraining, fine-tuning하면 더 나은 성능을 보여줄수 있다는 것을 보이는 것이다.**

# Abstract

&nbsp;&nbsp; 이 논문에서는 **adgerent rain drops and streaks**비가 내린(렌즈에 빗물이 묻은)상황에서 segmentation 수행을 향상시키는 방법을 제시하고 있다. 

* **사용 train dataset : stereo dataset**

&nbsp;&nbsp; - 두 개의 렌즈를 준비하여, 하나의 렌즈에는 실제 물방울이 영향을 미치게 하고, 다른 렌즈는 깨끗한 상태를 유지하게 하여 image를 수집함

이 데이터를 사용하여, denosing generator를 학습시키고, 이 모델이 image reconstruction과 road marking segmentation에서 실제 물방울의 영향을 제거하는데 효과적임을 보인다.

추가적으로 model의 성능을 test하기위해 컴퓨터로 생성된 물방울을 임의의 이미지에 추가하는 방법을 제안하였고, 이를 통해 general semantic segmentation에서의 성능을 평가하였다.

* **bench mark dataset : Cityscapes, 논문의 dataset, CamVid road marking segmentation dataset**

# 1. Introduction

![Image5](/assets/images/inpainting/ican/image5.jpg){: .align-center}

&nbsp;&nbsp; 우리가 야외에서 거리의 사진을 찍을 때, 비가 오는 상황이 발생할 수 있다. 이러한 경우에는 렌즈에 간섭이 생기며 Computer vision task 수행이 어려워진다. 그러나 왜곡은 noise가 아닌 구조이다.

&nbsp;&nbsp; 이 논문에서는 빗물의 영향을 제거하는 pre-processing step filter를 만드는 것이 목적이다. 다양한 vision task에서 빗방울로 인해 영향을 받는데, 특히 이 논문에서는 segmentation에 대해 효과를 test하기로 한다.

&nbsp;&nbsp; 그러나 이러한 연구를 진행하기 위해서 부딪히는 부분이 있다. 비가 오는 이미지를 수집하는데에는 많은 시간과 비용이 발생하고, ground truth나 supervised training에서는 불가능하다. 또한 augmented data로 다루기도 힘들다는 점이다.

&nbsp;&nbsp; 논문에서는 이미지 전처리 시스템을 만들고, 다른 방법으로 접근하며 이미지에서 수행되는 작업성능을 향상시킬 수 있는 배수된 이미지를 출력한다.

## 1.1 Dataset 구성

&nbsp;&nbsp; 먼저 두개의 렌즈를 준비하여, 하나의 렌즈에는 물방울의 영향을 받도록 하고, 다른 렌즈에는 건조한 상태로 유지되는 실제 소형 baseline 스테레오 데이터셋(bespoke real-world small baseline stereo dataset)을 만든다. 자세한 방법은 4-A에 나와있다.

&nbsp;&nbsp; 두번째로 GPU shader를 이용하여, 모든 이미지에 빗방울과 줄무늬를 컴퓨터로 생성하여 추가한다. 이에 대해서는 3-A에 나와있다. 이 때 이용한 데이터셋은 아래와 같다.
1. Cityscapes 
2. Oxford RobotCar dataset
3. CamVid

## 1.2 Benchmark de-raining model
벤치마크 데이터는 다음과 같다.
1. 빗물렌즈와 건조렌즈로 찍은 Road marking segmentation, restoration
2. Image reconstruction on the real-world dataset
3. 컴퓨터로 생성한 빗물을 추가한 CamVid, RobotCar image
4. 컴퓨터로 생성한 빗물을 추가한 Cityscapes

# 2. Related work

일반적으로, 이미지의 품질은 두가지 bad weather conditions에 영향을 받는다. 

1. **대기 오염물(contaminants in the atmosphere) :** 비, 안개, 스모그, 눈 등 대기 중 오염물은 시야를 방해하거나 장면을 부분적으로 가리지만, 이미지를 크게 왜곡하지 않는다. 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;관련 연구 :[12], [13], [14], [15], [16]
  
2. **부착된 오염물(adherent contaminants) :** 렌즈에 붙은 물방울은 이미지에 심한 왜곡을 발생시킨다. 이 것은 다양한 정도의 bluring을 유발하며, 대기 오염물과는 다른 광학적 특성을 가지고 있어 기존의 기술로는 개선하기 어렵다.

**여기서는 주로 물방울(2. adherent rain droplets)로 인해 왜곡된 이미지의 복원 기술에 대해 다룬다.**

## 2.1 Rain Modeling and Simulation

vision 분야에서는 여러 연구가 물방울의 구조 및 광학적 특성을 모델링하고자 했다.

- **RIGSEC model :** ([17], [18]) 물방울을 구의 단면으로 모델링하고, 중력의 영향을 고려하여 2D 베지어 곡선을 사용해 물방울의 물리적 형상을 계산하는 방법을 제안
- **dark band around the edges** ([19]): 물방울 경계 주변의 dark band를 모델링하여, 간단한 모델로도 물방울 표면 위의 이미지 왜곡을 정확히 보정
  
이 논문에서는 [17], [18], [19]의 연구를 바탕으로, 메타볼 방식과 유사하게 변형 및 결합할 수 있는 프로토 물방울 노멀 맵을 저장하는 단순한 합성 물방울 모델을 개발하였다.

**추가로, 물방울 제거 기술의 성능을 벤치마킹하기 위한 소규모 데이터셋이 생성되었다.**

- (21): 물이 뿌려진 유리판을 카메라 앞에 놓고 촬영했으나, 조명 및 장면의 변화로 인해 명확한 참조 데이터는 제공되지 않음.
- (22): 유리판에 뿌려진 물방울의 위치에 대한 참조 데이터만 제공하며 물방울 탐지 및 제거 성능을 연구
- (11): 최초로 정확한 참조 데이터를 제공하는 데이터셋을 생성하여, 물방울이 있는 장면과 없는 장면을 비교할 수 있게 했으나, 이는 대량의 이미지가 필요한 딥러닝 기술에 충분히 대응하기에 한계.

이 논문은 다양한 물방울 크기와 유형을 포함한 동적 장면의 시퀀셜 데이터셋을 정확한 참조 데이터와 함께 제공한 첫 번째 연구이다.

## 2.2 Raindrop Detection and Removal

- **match a template :** ([17], [18]) 가상의 물방울 템플릿을 사용하여 실제 물방울 위치를 추정하나, 실제 물방울 모양이 템플릿과 다를 경우 한계가 발생
- **observing that the motion inside droplets :** ([22]) 물방울 내의 움직임이 장면의 움직임보다 1/30에서 1/20 정도 느리다는 점을 이용하여 물방울을 탐지하고, 이미지 인페인팅 및 복원 기법을 사용해 이미지 복원

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**이러한 기술은 다중 프레임 정보를 사용하여 이미지 복원에 접근하므로 단일 이미지에는 적용할 수 없다.**

- **Multi-camera and pan-tilt setup :** ([23], [24], [25], [26]) 두 카메라 간의 시차를 이용해 물방울을 탐지하고 한 렌즈의 영향을 받은 부분을 다른 렌즈의 정보로 대체,

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**단일 이미지에 적용할 수 없으며, 두 프레임 모두 동일한 영역이 가려지지 않는다는 가정이 필요**

## 2.3 Deep learning based

- **CNN :**  ([21]) 3층 구조의 CNN을 사용해 작은 물방울에는 효과적이나, 큰 오염물에는 한계

- **GAN :** ([11]) GAN 모델과 attention([28])을 사용해 물방울 위치 히트맵을 생성하고, 이를 입력 이미지와 결합하여 복원 성능을 향상 시킴. 이 데이터셋을 공개함으로써 본 연구에서도 해당 데이터셋과 비교할 수 있었음.

# 3. Learning to Clean Iamges

## A. Computer-Generated Synthetic Rain

본 연구에서는 [17], [18], [19]의 연구를 기반으로 간단한 합성 물방울 모델을 사용하여 물방울의 위치를 간단한 통계적 접근법으로 생성하고, 물방울 간 상호작용을 메타볼(metaballs) 방식 [20]으로 모델링한 후 GPU 셰이더를 사용해 효율적으로 렌더링한다.

![Image6](/assets/images/inpainting/ican/image6.jpg){: .align-center}

- **proto-raindrop :** 핀홀 카메라를 가정한 단순한 굴절 모델을 사용하여 생성되며, 굴절 각도는 텍스처 T의 RED와 GREEN 채널을 사용한 2D 룩업 테이블을 통해 인코딩되고, 물방울 두께는 BLUE 채널에 인코딩됩니다. 이 텍스처는 알파 레이어로 마스킹되어 배경 이미지와 다른 물방울과 혼합된다.
  
- **distoration model :** 물방울 표면의 위치 $(u, v)$에 렌더링된 세계 좌표 $(x_{r}, y_{r})$는 다음과 같은 단순화된 왜곡 모델에 의해 계산된다.

    $$
    x_{r} = u + (R ∗ B)
    $$

    $$
    y_{r} = v + (G ∗ B)
    $$

- **물방울 슬립(Slip)**: 각 이미지 위치 $(u, v)$는 가로와 세로 방향으로 임의 값 $S_{x}$ 및 $S_{y}$로 스케일된 프리-물방울의 중심이 될 확률 $P_{r}$을 가진다. 물방울 지름 $d$가 4mm를 넘으면 가로 $D_{x}$, 세로 $D_{y}$ 픽셀만큼 미끄러질 수 있다.

각 시간 단계마다 가까운 물방울은 메타볼 방식으로 병합되며, 기본적으로 텍스처 $T(u, v)$는 물방울 아래에 속하지 않는 위치에서는 배경 이미지에 수직인 노멀을 인코딩한다.

이 기법을 통해 다음과 같은 세 가지 합성 비 데이터셋을 생성했다.

- **CamVid 데이터셋**: 합성 비가 추가된 데이터셋과 도로 표시 참조 데이터 포함
- **Cityscapes 데이터셋**: 합성 비와 의미적 분할 참조 데이터 포함
- **rain added to the dry our stereo  데이터셋**: 합성 비와 도로 표시 참조 데이터 포함

## B. The de-raining network

비 제거 네트워크 아키텍처는 Pix2PixHD [30]를 기반으로 하며, Fig. 2에 그 구조가 제시되어 있다.

![Image1](/assets/images/inpainting/ican/image1.jpg){: .align-center}

- **구조 :** 2배 stride의 4개의 down convolution layer, 9개의 ResNet [31] 블록, 4개의 up convolution layer로 구성 
- **skip connection**: 입력 이미지의 대부분의 구조, 조명 수준 및 세부 사항을 유지하기 위해 추가
- **loss funcion**: 일반화 및 인페인팅을 위해 직접적인 픽셀 단위 손실을 사용하지 않고, combination of adversarial, perceptual, multi-scale discriminator feature loss를 조합하여 사용, discriminator 아키텍처는 PatchGAN [32]과 유사한 5개의 레이어로 구성된 CNN

## C. Loss Function

- **adversarial loss :** ([33] 유사) generator의 출력에 discriminator를 적용하여 계산
  
  $$
  L_{adv} = (D(G(I_{rainy})) - 1)^2
  $$

- **discriminator loss :** 판별기를 훈련하여 명확한 이미지와 이전에 비 제거된 이미지에서 추출한 샘플로 손실을 최소화

  $$
  L_{disc} = (D(I_{clear}) - 1)^2 + (D(I_{de-rained}))^2
  $$

- **perceptual(인식적) loss** ([34]): VGG 네트워크의 여러 레이어를 사용해 라벨과 복원된 이미지 간 차이를 계산

  $$
  L_{perc} = \sum_{i=1}^{n_{VGG}} \frac{1}{w_{perc}^i} \| VGG(I_{clear})^i - VGG(G(I_{rainy}))^i \|_1
  $$

- **multi-scale discriminator feature loss** ([30]): 라벨과 복원된 이미지 간 다중 스케일에서의 discriminator 특징 손실을 계산

  $$
  L_{msadv} = \sum_{i=1}^{n_{ADV}} \frac{1}{w_{adv}^i} \| D(I_{clear})^i - D(G(I_{rainy}))^i \|_1
  $$

- **generator object loss**: 최종적으로 loss function은 다음과 같다.

  $$
  L_{gen} = \lambda_{adv} \times L_{adv} + \lambda_{perc} \times L_{perc} + \lambda_{msadv} \times L_{msadv}
  $$

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**각 $(\lambda)$ 값은 weight hyperparameter**

**Generator Function \(G\)는 아래를 최소화하도록 학습**

  $$
  G = \arg \min_{G,D} (L_{gen} + L_{disc})
  $$


# 4. EXPERIMENTAL SETUP

## A. Stereo Rain Dataset

![Image2](/assets/images/inpainting/ican/image2.jpg){: .align-center}
![Image3](/assets/images/inpainting/ican/image3.jpg){: .align-center}
![Image4](/assets/images/inpainting/ican/image4.jpg){: .align-center}

- **장비 설명 :** 좁은 간격 스테레오 카메라 세트를 사용하여 한쪽 렌즈만 물방울에 영향을 받게 함.
- **구성 :** 이중 챔버로 좌측은 건조하게 유지하고, 우측은 내장된 노즐로 물방울을 분사.
- **조정 가능 :** 챔버 각도 및 렌즈와의 거리 조정으로 다양한 물방울 초점과 흐림 정도 재현.
- **수집 데이터 :** 약 5만 개의 이미지 쌍을 기록하여 4818개는 학습, 검증, 테스트에 사용하며, 500개의 이미지에 대해 도로 표시 구분 기준 데이터 제공.

## B. Training

- **학습 방식 :** Adam optimization (learning rate: 0.0002, batch size: 1)
- **목적 :** 각 epoch에서 우선 discriminator를 학습해 $L_{disc}$를 최소화 한 후, 이후 generator를 학습해 $L_{gen}$를 최소화

## C. Segmentation Tasks
- **Road marking segmentation :** U-Net을 사용해 도로 마킹을 이진 분류.
- **Semantic segmentation :** Cityscapes 데이터셋에 대해 DeepLab v3를 사용하여 성능 평가.
- **Speed :** Nvidia Titan X GPU, 1280×960 해상도는  1Hz, 640×480 해상도는 약 3Hz 처리.

# 5. Results


## A. Quantitative Results

### 1. Road Marking Segmentation

- **Dataset :** RobotCar(real rain drops, R), RobotCar(computer-generated rain drops, S), CamVid(computer-generated rain drops, S)
- **Baseline :** 맑은 날씨에서 수집된 이미지로 학습된 모델을 사용하여, 맑은 날씨 이미지에서 테스트한 결과
- **RAINY :** 맑은 날씨 이미지로 학습된 모델을 빗방울이 있는 이미지로 테스트한 결과 (성능이 크게 저하됨)
- **AUGM :** 빗방울이 있는 이미지로 모델을 재학습한 경우의 성능 (성능 향상)
- **DERAINED :** 빗방울 제거 전처리를 수행한 후 맑은 날씨에서 학습된 모델로 테스트한 경우의 성능 (기준 성능에 근접)

| **TABLE I: Road Marking Segmentation Results** |
|-------------|--------------------|-------------------|------------------|------------------|
| Dataset     | **REFERENCE (CLEAR)**             | **RAINY**                      | **AUGM.**                     | **DERAINED**                   |
|             | Prec.   | Rec.    | F1     | IOU    | Prec.   | Rec.    | F1     | IOU    | Prec.   | Rec.    | F1     | IOU    | Prec.   | Rec.    | F1     | IOU    |
| **RobotCar(R)** | 0.627   | 0.918   | 0.734  | 0.594  | 0.512   | 0.628   | 0.550  | 0.396  | 0.486   | 0.807   | 0.593  | 0.434  | 0.603   | 0.841   | 0.689  | 0.544  |
| **RobotCar(S)** | 0.627   | 0.918   | 0.734  | 0.594  | 0.364   | 0.595   | 0.437  | 0.287  | 0.654   | 0.770   | 0.690  | 0.541  | 0.661   | 0.816   | 0.715  | 0.569  |
| **CamVid(S)**   | 0.5763  | 0.9269  | 0.6992 | 0.5512 | 0.3533  | 0.5762  | 0.4248 | 0.2787 | 0.4568  | 0.7707  | 0.5635 | 0.4051 | 0.5198  | 0.7553  | 0.6030 | 0.4438 |



- **결론**: 빗방울 제거 전처리(de-raining)를 수행한 후 맑은 날씨 학습 모델로 테스트했을 때, 세그멘테이션 성능이 크게 향상되었으며, 이는 데이터 증강보다 우수한 성능을 보여줌.

### 2. 시맨틱 세그멘테이션 (Semantic Segmentation) - Cityscapes 데이터셋

4가지 모델과 데이터셋 조합을 벤치마킹함:
- **CLEAR on CLEAR**: 맑은 날씨에서 학습 및 테스트
- **RAINY on CLEAR**: 맑은 날씨에서 학습하고 빗방울 이미지로 테스트 (성능 저하)
- **RAINY on AUGMENTED**: 맑은 날씨와 빗방울 이미지를 함께 학습
- **DERAINED on CLEAR**: 빗방울 제거 전처리 후 맑은 날씨에서 학습된 모델로 테스트 (성능 향상)

| Model vs. Dataset            | mIOU  |
|------------------------------|-------|
| CLEAR on CLEAR               | 0.692 |
| RAINY on CLEAR               | 0.405 |
| RAINY on AUGMENTED           | 0.611 |
| DERAINED on CLEAR            | 0.651 |

- **결론**: 빗방울 제거를 거친 이미지의 성능이 데이터 증강으로 학습한 모델보다 우수함.

## B. 복원 결과 (Reconstruction Results)

### 평가 지표

- **PSNR**: 높은 값일수록 이미지 품질이 우수
- **SSIM**: 구조적 유사성 지수, 1에 가까울수록 원본과 유사

| **TABLE III: Reconstruction Results** | | | | |
|----------------|---------|---------|--------|--------|
| Dataset        | RAW (PSNR) | RAW (SSIM) | DERAINED (PSNR) | DERAINED (SSIM) |
| RobotCar-Rainy (R) | 13.02   | 0.5574 | 22.82 | 0.8188 |
| RobotCar-Rainy (S) | 16.80   | 0.6134 | 25.17 | 0.8699 |
| CamVid-Rainy (S)    | 16.89   | 0.6064 | 22.11 | 0.7524 |
| Qian et al.[11](R)  | 24.09   | 0.8518 | 31.55 | 0.9020 |

- **결론**: 빗방울 제거 후 모든 데이터셋에서 PSNR과 SSIM 점수가 상승하여 이미지 품질이 개선됨을 확인.

### 복원 품질 비교 (Reconstruction Quality Comparison to State-of-the-Art)

| Model vs. Dataset       | Dataset from [11] |
|-------------------------|-------------------|
|                         | PSNR | SSIM       |
| Original                | 24.09 | 0.8518    |
| Eigen13[21]             | 28.59 | 0.6726    |
| Pix2Pix[37]             | 30.14 | 0.8299    |
| Qian et al.(no att.)[11]| 30.88 | 0.8670    |
| Qian et al.(full att.)[11] | 31.51 | 0.9213 |
| Ours (no att.)          | 31.55 | 0.9020    |

- **결론**: 최신 기법과 비교했을 때,attention 메커니즘 없이도 높은 PSNR과 SSIM 성능을 기록하여, 모델의 단순화와 효율성 향상에 기여함.

# 6. Conclusions

&nbsp;&nbsp;논문에서는 빗방울이 묻은 이미지에서 중요한 세분화 작업의 성능을 복원하는 시스템을 제시했다. 자율 주행 시스템에 중요한 작업인 도로 표시 세분화가 빗방울로 인해 심각하게 영향을 받으며, 이미지를 먼저 제거하는 전처리 과정을 거치면 성능이 복원될 수 있음을 보여준다. 마찬가지로, 여러 분야에서 중요한 작업인 의미 세분화의 경우에도 성능 저하 및 복원이 동일하게 나타났다. 또한, 실시간으로 실행할 수 있는 상태에서 이미지 복원의 품질 측면에서 좋은 결과를 도출했다.

&nbsp;&nbsp;마지막으로, 이 시스템은 세분화 파이프라인 외부에서 이미지 스트림을 오프라인 또는 온라인으로 처리하므로 많은 기존 시스템의 프런트엔드로 자연스럽게 사용할 수 있다. 데이터셋은 [https://ciumonk.github.io/RobotCar-rainy/](https://ciumonk.github.io/RobotCar-rainy/)에서 제공되며, 결과에 대한 동영상은 [https://ciumonk.github.io/RobotCar-rainy/video.html](https://ciumonk.github.io/RobotCar-rainy/video.html)에서 확인할 수 있다.

# 7. Future Work

향컴퓨터 생성된 비가 이미지 기반 작업의 성능을 질적으로 개선하는 것이 아니라 정량적으로 향상시키는 데 유용하다는 점에서 실제 비와 구별할 수 없는 메커니즘을 설계하는 작업이 포함될 수 있다.


