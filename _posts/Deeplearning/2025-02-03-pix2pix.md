---
layout: single
title: "Image-to-Image Translation with Conditional Adversarial Networks" #제목
excerpt : ""
categories: 
    - deeplearningCV #카테고리설정
tag: 
    - [] #테그

date: 2025-02-03
last_modified_at: 2025-02-03
classes: wide    
---
[Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/pdf/1611.07004){: .btn .btn--primary}


# Abstract

&nbsp;&nbsp; 이 논문에서는 image translation에 대한 일반적인 solution으로 사용하는 GAN에 대해 연구한다. 이 network는 input image to output image로의 mapping만 학습할 뿐만 아니라, mapping을 위한 loss function도 학습한다. 이는 다른 loss 공식이 필요한 문제에 대해서도 같은 포괄적인 접근을 가능하게 한다. 논문에서는 이를 통해 photos from labels map, reconstructing object from edge maps, colorizing 등 다양한 이미지 합성에서 효과적인 성능을 보이는 것을 증명했으며, **pix2pix** 출시 이후에 많은 사람들이 이 시스템을 사용하는 것을 보면서 parameter 조정 없이 다양한 곳에서 적용할 수 있음을 보였다. 

# 1. Introduction
![Image5](/assets/images/pix2pix/image1.jpg){: .align-center}

&nbsp;&nbsp; 많은 image processing, computer vision에서의 문제들은 input image를 관련된 output image로 변환하는 것이다. 이 개념은 언어를 번혁하는 것처럼 RGB, gradient field, edge map, semantic label map 등에서 다양하게 rendering 될 수 있다. 자동 언어 번역이 가능한 것처럼 논문에서는 충분한 training data가 주어졌을 때, 자동 image to image task를 정의하였다. 기존의 논문들에서는 이러한 다양한 task를 각 별도에 맞도록 처리하였다. 이 논문에서의 목표는 이러한 다양한 문제들에 대해 공통적인 framework를 개발하는 것이다. 

&nbsp;&nbsp; 이 연구 방안에서 CNN을 통한 광범위한 연구가 진행되었고, loss function을 최소화 하는 방법으로 좋은 성능을 보여왔다. 그러나 효과적인 loss를 design하기 위해서는 많은 작업이 필요하다. CNN을 predict와 ground truth의 Eclidean distance로 최소화한다면, 결과물이 흐려지는 경향이 있기 때문이다.(Eclidean distance는 결과의 모든 값을 평균화 하기 때문에 blur가 생김.)

&nbsp;&nbsp; 만약 reality와 구분할 수 없는 output을 만드는 것처럼 high level을 달성하기 위해 loss function을 적절하게 설정한다면, 매우 바람직할 것이다. GAN model은 이를 수행할 수 있으며, output이 real인지 fake인지 구분하는 discriminator loss와 generator loss를 사용하여 학습한다. 이 때, blur된 이미지는 fake로 보이기 때문에 선명한 image를 생성할 수 있게 된다. 논문에서는 GANs의 conditional setting에 대해 탐구하고, data 생성 모델을 학습하는 것처럼 Conditional GANs는 conditional 생성모델을 학습한다. 따라서 cGAN은 conditional input image에 따라서 output을 생성하는 image translation task에서 적합하다.

# 2. Related work

1. Strucured losses for image modeling

2. Conditional GANs

# 3. Method

![Image5](/assets/images/pix2pix/image2.jpg){: .align-center}

&nbsp;&nbsp; GANs은 random noise vector $z$로 output image $y$, $G : z \to y$ 로의  mapping을 학습하는 생성모델이다. 반면, conditional GANs는 관측 이미지 $x$, random noise vector $z$로 $y$, $G : (x,z) \to y$ 로의 mapping을 학습하는 모델이다.  G는 output이 real인지 fake인지 구분할 수 없도록 학습되고, D는 이것을 구분할 수 있도록 학습된다. 

## 3.1 Objective

$$
\mathcal{L}_{\text{cGAN}}(G, D) = \mathbb{E}_{x,y} [\log D(x, y)] + \mathbb{E}_{x,z} [\log (1 - D(x, G(x, z)))]
$$

&nbsp;&nbsp; conditioning Discriminator의 중요성을 test하기 위해, $x$를 고려하지 않는 unconditional도 함께 비교한다. 

$$
\mathcal{L}_{\text{GAN}}(G, D) = \mathbb{E}_{y} [\log D(y)] + \mathbb{E}_{x,z} [\log (1 - D(x, G(x, z)))]
$$

&nbsp;&nbsp; 이전의 접근법들은 전통적인 loss와 GAN의 objective를 조합하는 것이 유용하다고 나와있다. Discriminator의 역할은 변하지 않지만, generator의 task가 discriminator뿐만 아니라 ground truth image와 유사해야하기 때문에, L2 loss를 사용하는 것이 도움이 된다. 그러나 논문에서는 L2 loss보다 L1이 blurring이 적다는 것을 발견했기 때문에 최종적으로 generator에 L1 loss를 결합하여 사용한다. 

$$
\mathcal{L}_{L1}(G) = \mathbb{E}_{x,y,z} \left[ \| y - G(x, z) \|_1 \right].
$$

따라서 최종적인 목적함수는 다음과 같다.

$$
G^* = \arg \min_G \max_D \mathcal{L}_{\text{cGAN}}(G, D) + \lambda \mathcal{L}_{L1}(G)
$$

&nbsp;&nbsp; $z$ 없이 $x$를 $y$로의 mapping을 model이 학습할 수 있지만, 결정적인(determinstic) output을 생성하기 때문에 delta function의 분포로만 표현 가능하고, 다른 것들은 표현할 수 없다. 과거 Past Conditional GANs의 연구에서는 이것을 인정하고, Gaussian noise $z$를 추가하여 실험을 진행하였지만, 이것이 효과적이지 않았고 즉, Generator는 noise를 무시한다는 것을 알았다. 따라서 논문에서는 noise $z$를 Generator에 넣지 않고, Dropout을 사용하였다. 그럼에도 불구하고 drop out을 사용한 것에서는 minor stocahsticity만 발견되었고, noise를 사용한것과 같은 분포가 나오지 않았다. 이 부분은 이 연구에서 해결되지 않은 중요한 문제이다.

