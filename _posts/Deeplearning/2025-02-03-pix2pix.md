---
layout: single
title: "Image-to-Image Translation with Conditional Adversarial Networks" #제목
excerpt : ""
categories: 
    - deeplearningCV #카테고리설정
tag: 
    - [] #테그

date: 2025-02-03
last_modified_at: 2025-02-03
classes: wide    
---
[Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/pdf/1611.07004){: .btn .btn--primary}


# Abstract

&nbsp;&nbsp; 이 논문에서는 image translation에 대한 일반적인 solution으로 사용하는 GAN에 대해 연구한다. 이 network는 input image to output image로의 mapping만 학습할 뿐만 아니라, mapping을 위한 loss function도 학습한다. 이는 다른 loss 공식이 필요한 문제에 대해서도 같은 포괄적인 접근을 가능하게 한다. 논문에서는 이를 통해 photos from labels map, reconstructing object from edge maps, colorizing 등 다양한 이미지 합성에서 효과적인 성능을 보이는 것을 증명했으며, **pix2pix** 출시 이후에 많은 사람들이 이 시스템을 사용하는 것을 보면서 parameter 조정 없이 다양한 곳에서 적용할 수 있음을 보였다. 

# 1. Introduction
![Image5](/assets/images/pix2pix/image1.jpg){: .align-center}

&nbsp;&nbsp; 많은 image processing, computer vision에서의 문제들은 input image를 관련된 output image로 변환하는 것이다. 이 개념은 언어를 번혁하는 것처럼 RGB, gradient field, edge map, semantic label map 등에서 다양하게 rendering 될 수 있다. 자동 언어 번역이 가능한 것처럼 논문에서는 충분한 training data가 주어졌을 때, 자동 image to image task를 정의하였다. 기존의 논문들에서는 이러한 다양한 task를 각 별도에 맞도록 처리하였다. 이 논문에서의 목표는 이러한 다양한 문제들에 대해 공통적인 framework를 개발하는 것이다. 

&nbsp;&nbsp; 이 연구 방안에서 CNN을 통한 광범위한 연구가 진행되었고, loss function을 최소화 하는 방법으로 좋은 성능을 보여왔다. 그러나 효과적인 loss를 design하기 위해서는 많은 작업이 필요하다. CNN을 predict와 ground truth의 Eclidean distance로 최소화한다면, 결과물이 흐려지는 경향이 있기 때문이다.(Eclidean distance는 결과의 모든 값을 평균화 하기 때문에 blur가 생김.)

&nbsp;&nbsp; 만약 reality와 구분할 수 없는 output을 만드는 것처럼 high level을 달성하기 위해 loss function을 적절하게 설정한다면, 매우 바람직할 것이다. GAN model은 이를 수행할 수 있으며, output이 real인지 fake인지 구분하는 discriminator loss와 generator loss를 사용하여 학습한다. 이 때, blur된 이미지는 fake로 보이기 때문에 선명한 image를 생성할 수 있게 된다. 논문에서는 GANs의 conditional setting에 대해 탐구하고, data 생성 모델을 학습하는 것처럼 Conditional GANs는 conditional 생성모델을 학습한다. 따라서 cGAN은 conditional input image에 따라서 output을 생성하는 image translation task에서 적합하다.

# 2. Related work

1. Strucured losses for image modeling

2. Conditional GANs

# 3. Method

![Image5](/assets/images/pix2pix/image2.jpg){: .align-center}

&nbsp;&nbsp; GANs은 random noise vector $z$로 output image $y$, $G : z \to y$ 로의  mapping을 학습하는 생성모델이다. 반면, conditional GANs는 관측 이미지 $x$, random noise vector $z$로 $y$, $G : (x,z) \to y$ 로의 mapping을 학습하는 모델이다.  G는 output이 real인지 fake인지 구분할 수 없도록 학습되고, D는 이것을 구분할 수 있도록 학습된다. 

## 3.1 Objective

$$
\mathcal{L}_{\text{cGAN}}(G, D) = \mathbb{E}_{x,y} [\log D(x, y)] + \mathbb{E}_{x,z} [\log (1 - D(x, G(x, z)))]
$$

&nbsp;&nbsp; conditioning Discriminator의 중요성을 test하기 위해, $x$를 고려하지 않는 unconditional도 함께 비교한다. 

$$
\mathcal{L}_{\text{GAN}}(G, D) = \mathbb{E}_{y} [\log D(y)] + \mathbb{E}_{x,z} [\log (1 - D(x, G(x, z)))]
$$

&nbsp;&nbsp; 이전의 접근법들은 전통적인 loss와 GAN의 objective를 조합하는 것이 유용하다고 나와있다. Discriminator의 역할은 변하지 않지만, generator의 task가 discriminator뿐만 아니라 ground truth image와 유사해야하기 때문에, L2 loss를 사용하는 것이 도움이 된다. 그러나 논문에서는 L2 loss보다 L1이 blurring이 적다는 것을 발견했기 때문에 최종적으로 generator에 L1 loss를 결합하여 사용한다. 

$$
\mathcal{L}_{L1}(G) = \mathbb{E}_{x,y,z} \left[ \| y - G(x, z) \|_1 \right].
$$

따라서 최종적인 목적함수는 다음과 같다.

$$
G^* = \arg \min_G \max_D \mathcal{L}_{\text{cGAN}}(G, D) + \lambda \mathcal{L}_{L1}(G)
$$

&nbsp;&nbsp; $z$ 없이 $x$를 $y$로의 mapping을 model이 학습할 수 있지만, 결정적인(determinstic) output을 생성하기 때문에 delta function의 분포로만 표현 가능하고, 다른 것들은 표현할 수 없다. 과거 Past Conditional GANs의 연구에서는 이것을 인정하고, Gaussian noise $z$를 추가하여 실험을 진행하였지만, 이것이 효과적이지 않았고 즉, Generator는 noise를 무시한다는 것을 알았다. 따라서 논문에서는 noise $z$를 Generator에 넣지 않고, Dropout을 사용하였다. 그럼에도 불구하고 drop out을 사용한 것에서는 minor stocahsticity만 발견되었고, noise를 사용한것과 같은 분포가 나오지 않았다. 이 부분은 이 연구에서 해결되지 않은 중요한 문제이다.


## 3.2 Network architectures

&nbsp;&nbsp; 논문에서는 DCGAN 구조를 채택하였고, generator, discriminator 모두 batch normalization에 소개 된 con-BatchNorm-ReLU 구조를 사용하였다. 


![Image5](/assets/images/pix2pix/image3.jpg){: .align-center}

### 3.2.1 Generator with skips

&nbsp;&nbsp; image-to-image translation에서 문제의 특징은 high-resolution input grid를 high-resoultion output grid로 mapping한다는 것이다. 이 문제에서 고려해야하는 문제는 input과 output가 표면적으로는 다르지만 같은 구조를 rendering해야한다는 것이다. 그러므로 input의 구조는 output의 구조와 약간 정렬되어 있어야한다. 논문에서는 이 사항을 중심으로 Generator architecture를 구성한다.
&nbsp;&nbsp; 많은 이전 연구들에서는 encoder-decoder network를 사용한다. 이 network는 input이 bottleneck layer까지 downsampling되는 layer를 통과한다. 이런 network는 bottleneck을 포함한 모든 layer를 통해 정보의 흐름이 전달 되어야한다. 많은 image translation 문제에서 input과 output 사이에 low-level 정보가 공유되고, network를 통해 직접적으로 전달되는 것이 이상적이다. 예를 들어 colorization에서는 input과 output이 확실한 edge의 위치 정보를 공유한다.
&nbsp;&nbsp; 또한 bottleneck으로 인해 정보가 손실되는 것을 방지하기 위해 Unet과 같이 skip connection을 사용하는데, 각 pair 사이의 skip connection을 추가한다. 

### 3.2.2 Markovian discriminator(Patch GAN)

&nbsp;&nbsp; L2 loss, L1 loss가 image 생성에서 blur효과가 나타난다는 것은 잘 알려져있다. 그럼에도 불구하고 L1, L2 loss는 high frequency를 잘 잡아내지 못하지만, low frequencies에서는 정확하게 잡아낸다. 그래서 논문에서는 L1 term을 사용하고, high-frequency를 잡아내기 위해 GAN을 사용한다. 또한 local image patch를 사용하여 high-frequency를 잡아내며 각 $ N X N $의 patch가 real인지 분류하여 Discriminator의 output으로 반환한다.

&nbsp;&nbsp; 챕터 4.4에서는 $N$이 full size의 이미지보다 매우 작아도 high quality를 유지한다는 것을 증명하고, 작은 PatchGAN은 parameter수가 적으며, 빠르게 작동하고 큰 image에 대해서도 적용가능하다는 장점을 가지고 있다.

&nbsp;&nbsp; discriminator는 patch의 크기보다 먼 pixel간에는 독립적이라고 가정하며 Markov random filed에서 효과적이다.

## 3.3 Optimization and inference

&nbsp;&nbsp; 논문의 network를 최적화하기 위해 GAN의 approach를 따르며, $D,G$를 번갈하 가며 gradient descent를 진행한다. GAN에서는 $G$에서 $\log (1 - D(x, G(x, z)))$를 최소화 하도록 학습하는데, 논문에서는 $\log D(x,G(x,z)) $ 를 최대화 하는 방법을 사용하고, $D$의 loss함수를 2로 나누어 학습 속도를 늦춘다. training시에는 minibatch SGD를 사용하고 Adam optimizer를 사용하며, learning rate = 0.0002, momentum의 parameter는 $\beta_1 = 0.5, \beta_2 = 0.999$ 이다.