---
layout: single
title: "One-Step Image Translation with Text-to-Image Models" #제목
excerpt : ""
categories: 
    - deeplearningCV #카테고리설정
tag: 
    - [] #테그

date: 2025-01-31
last_modified_at: 2025-01-31
classes: wide    
---
[One-Step Image Translation with Text-to-Image Models](https://arxiv.org/pdf/2403.12036){: .btn .btn--primary}


# 0. Abstract

논문에서는 기존 conditional diffusion model(Image translation task)에서 두가지 한계점으로 인한 느린 inference speed를 극복하려한다.

* 두가지 한계점
    1. 반복적인 denoising 과정
    2. paired 데이터에 의존해야함

* 해결 방법
    1. 기존의 latent diffusion model의 다양한 module들을 하나로 통합하여 end-to-end generator로 통합시킴
    2. 적은 trainable한 weight를 추가하여 input image의 구조를 유지하며 overfitting을 방지

이 논문은 unpaired data에 대해서는 CycleGAN-turbo model을 사용하고, paired data에 대해서는 pix2pix-turbo model을 제시하였으며, 성능은 GAN based, diffusion based 보다 우수한 성능을 보였다.

# 1. Introduction

&nbsp;&nbsp; conditional diffusion model은 user가 이미지를 생성하는데 spatial conditioning, text prompts를 이용할 수 있기 때문에, scene layout, user sketches, human pose 등 다양한 image 합성에 사용이 가능했다. 그러나 이 모델에는 두가지 challenge가 존재한다.

    1. Diffusion model은 반복을 통해 진행되기 때문에 inference 속도가 매우 느리다.
    2. 학습을 위해 paired 데이터를 수집해야하는데, 이것은 많은 cost가 발생한다.

