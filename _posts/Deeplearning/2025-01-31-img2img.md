---
layout: single
title: "One-Step Image Translation with Text-to-Image Models" #제목
excerpt : ""
categories: 
    - deeplearningCV #카테고리설정
tag: 
    - [] #테그

date: 2025-01-31
last_modified_at: 2025-01-31
classes: wide    
---
[One-Step Image Translation with Text-to-Image Models](https://arxiv.org/pdf/2403.12036){: .btn .btn--primary}


# 0. Abstract

논문에서는 기존 conditional diffusion model(Image translation task)에서 두가지 한계점으로 인한 느린 inference speed를 극복하려한다.

* 두가지 한계점
    1. 반복적인 denoising 과정
    2. paired 데이터에 의존해야함

* 해결 방법
    1. 기존의 latent diffusion model의 다양한 module들을 하나로 통합하여 end-to-end generator로 통합시킴
    2. 적은 trainable한 weight를 추가하여 input image의 구조를 유지하며 overfitting을 방지

이 논문은 unpaired data에 대해서는 CycleGAN-turbo model을 사용하고, paired data에 대해서는 pix2pix-turbo model을 제시하였으며, 성능은 GAN based, diffusion based 보다 우수한 성능을 보였다.

# 1. Introduction

&nbsp;&nbsp; conditional diffusion model은 user가 이미지를 생성하는데 spatial conditioning, text prompts를 이용할 수 있기 때문에, scene layout, user sketches, human pose 등 다양한 image 합성에 사용이 가능했다. 그러나 이 모델에는 두가지 challenge가 존재한다.

    1. Diffusion model은 반복을 통해 진행되기 때문에 inference 속도가 매우 느리다.
    2. 학습을 위해 paired 데이터를 수집해야하는데, 이것은 많은 cost가 발생한다.

&nbsp;&nbsp; 이러한 문제를 해결하기 위해 논문에서는 paired, unpaired dataset에 모두 적용 가능한 **one-step image-to-image translation** 방법을 제안한다. 이 방법은 기존의 CDM(conditional diffusion model)과 비교가능한 결과를 내고, 1번의 step으로 진행되기 떄문에 추론 속도가 빠르다. 가장 중요한점은 paired image set 없이도 학습이 가능하다는 점이다. 논문에서의 핵심아이디어는 SD-Turbo와 같은 충분히 pre-train된 데이터를 GAN과 같은 방법을 이용하여 적용하는 것이다. 

&nbsp;&nbsp; 기존의 diffusion model에서 논문의 저자들은 one-step model에서 <span style="color:red"> noise map </span>이 직접적으로 output 구조에 영향을 준다는 것을 발견하였다. 결과적으로 <span style="color:red"> adapter branch </span>를 추가하여 noise map과 input conditioning을 모두 먹이면 네트워크에 대한 정보가 충돌한다.

게다가 image-to-image translation에서 대부분 visual detail이 Encoder-Decoder 구조와 같은 pipeline에서 손상된다. 이 detail에 대한 loss는 day-to-night translation에서 아주 중요한 부분이다.

